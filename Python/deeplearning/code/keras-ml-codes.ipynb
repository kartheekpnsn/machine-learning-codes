{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sample Codes for Classification and Regression\n",
    "- Refer [this](https://github.com/kartheekpnsn/machine-learning-codes/blob/master/Python/deeplearning/code/keras-basics.ipynb) before going through the below code\n",
    "- More on tuning is given [here](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://blog.keras.io/img/keras-tensorflow-logo.jpg \"Keras with Tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"..//data//sonar_data.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The output variable is string values. We must convert them into integer values 0 and 1.\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Keras models with scikit-learn, we must use the KerasClassifier wrapper. This class takes a function that creates and returns our neural network model. It also takes arguments that it will pass along to the call to fit() such as the number of epochs and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 80.28% (4.66%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn = create_baseline, epochs = 100, batch_size = 5, verbose = 0)\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv = kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Run The Baseline Model With Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.13% (8.09%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Layers and Number of Neurons in The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate a Smaller Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 85.04% (7.38%)\n"
     ]
    }
   ],
   "source": [
    "# smaller model - reduce hidden layer neurons from 60 to 30\n",
    "def create_smaller():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate a Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 83.61% (7.57%)\n"
     ]
    }
   ],
   "source": [
    "# larger model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2) Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"..//data//boston_housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 57.74 (42.36) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Run The Baseline Model With Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 29.31 (27.77) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Layers and Number of Neurons in The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate a Deeper Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 23.39 (27.02) MSE\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate a Wider Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: 22.52 (29.53) MSE\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3) Tuning Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Batch Size and Number of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of epochs is the number of times that the entire training dataset is shown to the network during training.\n",
    "- Here we will evaluate a suite of different mini batch sizes from 10 to 100 in steps of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"..//data//pimas_diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Training Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"..//data//pimas_diabetes.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Learning Rate and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the learning rate and momentum\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"..//data//pimas_diabetes.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4) Functional API: Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has 10 inputs, 3 hidden layers with 10, 20, and 10 neurons, and an output layer with 1 output. Rectified linear activation functions are used in each hidden layer and a sigmoid activation function is used in the output layer, for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visible = Input(shape = (10, ))\n",
    "hidden1 = Dense(10, activation = 'relu')(visible)\n",
    "hidden2 = Dense(20, activation = 'relu')(hidden1)\n",
    "hidden3 = Dense(10, activation = 'relu')(hidden2)\n",
    "output = Dense(1, activation = 'sigmoid')(hidden3)\n",
    "\n",
    "model = Model(inputs = visible, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 551\n",
      "Trainable params: 551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5) Functional API: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model receives black and white 64×64 images as input, then has a sequence of two convolutional and pooling layers as feature extractors, followed by a fully connected layer to interpret the features and an output layer with a sigmoid activation for two-class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(64, 64, 1))\n",
    "conv1 = Conv2D(32, kernel_size = 4, activation = 'relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size = (2, 2))(conv1)\n",
    "conv2 = Conv2D(16, kernel_size = 4, activation = 'relu')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size = (2, 2))(conv2)\n",
    "hidden1 = Dense(10, activation = 'relu')(pool2)\n",
    "output = Dense(1, activation = 'sigmoid')(hidden1)\n",
    "\n",
    "model = Model(inputs = visible, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 61, 61, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 27, 27, 16)        8208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 13, 13, 10)        170       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 13, 13, 1)         11        \n",
      "=================================================================\n",
      "Total params: 8,933\n",
      "Trainable params: 8,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 6) Functional API: RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model expects 100 time steps of one feature as input. The model has a single LSTM hidden layer to extract features from the sequence, followed by a fully connected layer to interpret the LSTM output, followed by an output layer for making binary predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visible = Input(shape = (100, 1))\n",
    "hidden1 = LSTM(10)(visible)\n",
    "hidden2 = Dense(10, activation = 'relu')(hidden1)\n",
    "output = Dense(1, activation = 'sigmoid')(hidden2)\n",
    "\n",
    "model = Model(inputs = visible, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 7) Functional API: Shared Input Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes black and white images with the size 64×64 pixels. There are two CNN feature extraction submodels that share this input; the first has a kernel size of 4 and the second a kernel size of 8. The outputs from these feature extraction submodels are flattened into vectors and concatenated into one long vector and passed on to a fully connected layer for interpretation before a final output layer makes a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visible = Input(shape = (64, 64, 1))\n",
    "# first feature extractor\n",
    "conv1 = Conv2D(32, kernel_size = 4, activation = 'relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size = (2, 2))(conv1)\n",
    "flat1 = Flatten()(pool1)\n",
    "# second feature extractor\n",
    "conv2 = Conv2D(16, kernel_size = 8, activation = 'relu')(visible)\n",
    "pool2 = MaxPooling2D(pool_size = (2, 2))(conv1)\n",
    "flat2 = Flatten()(pool2)\n",
    "# merge them\n",
    "merge = concatenate([flat1, flat2])\n",
    "# interpretation layer\n",
    "hidden1 = Dense(10, activation = 'relu')(merge)\n",
    "# output layer\n",
    "output = Dense(1, activation = 'sigmoid')(hidden1)\n",
    "\n",
    "model = Model(inputs = visible, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 61, 61, 32)    544         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)   (None, 30, 30, 32)    0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D)  (None, 30, 30, 32)    0           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 28800)         0           max_pooling2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 28800)         0           max_pooling2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 57600)         0           flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 10)            576010      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 1)             11          dense_17[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 576,565\n",
      "Trainable params: 576,565\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8) Functional API: Shared Feature Extraction Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the model is 100 time steps of 1 feature. An LSTM layer with 10 memory cells interprets this sequence. The first interpretation model is a shallow single fully connected layer, the second is a deep 3 layer model. The output of both interpretation models are concatenated into one long vector that is passed to the output layer used to make a binary prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visible = Input(shape = (100, 1))\n",
    "# feature extraction 1\n",
    "extract1 = LSTM(10)(visible)\n",
    "# first interpretation model\n",
    "interpret1 = Dense(10, activation = 'relu')(extract1)\n",
    "# second interpretation model\n",
    "interpret21 = Dense(10, activation = 'relu')(extract1)\n",
    "interpret22 = Dense(20, activation = 'relu')(interpret21)\n",
    "interpret23 = Dense(10, activation = 'relu')(interpret22)\n",
    "# merge layers\n",
    "merge = concatenate([interpret1, interpret23])\n",
    "# output layer\n",
    "output = Dense(1, activation = 'sigmoid')(merge)\n",
    "\n",
    "model = Model(inputs = visible, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 100, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 10)            480         input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 10)            110         lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 20)            220         dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 10)            110         lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 10)            210         dense_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 20)            0           dense_24[0][0]                   \n",
      "                                                                   dense_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 1)             21          concatenate_3[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 1,151\n",
      "Trainable params: 1,151\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 9) Functional API: Multiple Inputs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first input model\n",
    "visible1 = Input(shape=(64,64,1))\n",
    "conv11 = Conv2D(32, kernel_size=4, activation='relu')(visible1)\n",
    "pool11 = MaxPooling2D(pool_size=(2, 2))(conv11)\n",
    "conv12 = Conv2D(16, kernel_size=4, activation='relu')(pool11)\n",
    "pool12 = MaxPooling2D(pool_size=(2, 2))(conv12)\n",
    "flat1 = Flatten()(pool12)\n",
    "\n",
    "# second input model\n",
    "visible2 = Input(shape=(32,32,3))\n",
    "conv21 = Conv2D(32, kernel_size=4, activation='relu')(visible2)\n",
    "pool21 = MaxPooling2D(pool_size=(2, 2))(conv21)\n",
    "conv22 = Conv2D(16, kernel_size=4, activation='relu')(pool21)\n",
    "pool22 = MaxPooling2D(pool_size=(2, 2))(conv22)\n",
    "flat2 = Flatten()(pool22)\n",
    "\n",
    "# merge input models\n",
    "merge = concatenate([flat1, flat2])\n",
    "\n",
    "# interpretation model\n",
    "hidden1 = Dense(10, activation='relu')(merge)\n",
    "hidden2 = Dense(10, activation='relu')(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_12 (InputLayer)            (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_13 (InputLayer)            (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 61, 61, 32)    544         input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 29, 29, 32)    1568        input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D)  (None, 30, 30, 32)    0           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D)  (None, 14, 14, 32)    0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 27, 27, 16)    8208        max_pooling2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 11, 11, 16)    8208        max_pooling2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D)  (None, 13, 13, 16)    0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, 5, 5, 16)      0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 2704)          0           max_pooling2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 400)           0           max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 3104)          0           flatten_3[0][0]                  \n",
      "                                                                   flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 10)            31050       concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 10)            110         dense_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 1)             11          dense_30[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 49,699\n",
      "Trainable params: 49,699\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 10) Functional API: Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input layer\n",
    "visible = Input(shape=(100,1))\n",
    "\n",
    "# feature extraction\n",
    "extract = LSTM(10, return_sequences=True)(visible)\n",
    "\n",
    "# classification output\n",
    "class11 = LSTM(10)(extract)\n",
    "class12 = Dense(10, activation='relu')(class11)\n",
    "output1 = Dense(1, activation='sigmoid')(class12)\n",
    "\n",
    "# sequence output\n",
    "output2 = TimeDistributed(Dense(1, activation='linear'))(extract)\n",
    "\n",
    "model = Model(inputs=visible, outputs=[output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 100, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                    (None, 100, 10)       480         input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 10)            840         lstm_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 10)            110         lstm_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 1)             11          dense_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 100, 1)        11          lstm_8[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1,452\n",
      "Trainable params: 1,452\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
